{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4ee7ba-bdb3-4ef7-b46d-7d7b7fb676be",
   "metadata": {},
   "source": [
    "# OpenCV Docs\n",
    "Camera Calibration and 3D reconstruction:\n",
    "\n",
    "https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html\n",
    "\n",
    "Detection of ArUco Markers:\n",
    "\n",
    "https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e72f95-e556-401b-8787-c403d8bd840a",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed082f80-d48a-4714-9639-b1c36b9e3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Configuration\n",
    "FRAME_WIDTH = 1280 # [px]\n",
    "FRAME_HEIGHT = 720 # [px]\n",
    "ARUCO_DICT = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_50)\n",
    "NUM_MARKERS = 50\n",
    "MARKER_SIZE = 140 # [px]\n",
    "MARKER_BORDER_WIDTH = 20 # [%]\n",
    "MARKER_FOLDER = \"markers\"\n",
    "CHESSBOARD_DIMENSIONS = (10, 7)\n",
    "CHESSBOARD_SQUARE_SIZE = 80 # [px]\n",
    "CHESSBOARD_FILENAME = \"chessboard.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41aa611-3562-4b33-9053-a08a124ff8eb",
   "metadata": {},
   "source": [
    "# Generate ArUco Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed447f4a-d49a-478e-917c-4986b86700c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50 markers...\n",
      "------------------------------\n",
      "Generated 50 markers, 140x140 pixels with a 20% white border.\n",
      "Successfully saved markers to 'C:\\Users\\kwiat\\Documents\\GitHub\\Unitree-G1-3D-position-tracking\\markers'\n"
     ]
    }
   ],
   "source": [
    "# Create the output folder if it doesn't already exist\n",
    "if not os.path.exists(MARKER_FOLDER):\n",
    "    os.makedirs(MARKER_FOLDER)\n",
    "    print(f\"Folder '{MARKER_FOLDER}' created.\")\n",
    "\n",
    "print(f\"Generating {NUM_MARKERS} markers...\")\n",
    "\n",
    "# Loop to generate and save markers (IDs 0 to NUM_MARKERS-1)\n",
    "for marker_id in range(NUM_MARKERS):\n",
    "    # 1. Generate the base marker image (the black and white square)\n",
    "    marker_image = cv2.aruco.generateImageMarker(ARUCO_DICT, marker_id, MARKER_SIZE)\n",
    "\n",
    "    # 2. Calculate the border size in pixels\n",
    "    border_pixels = int(MARKER_SIZE * MARKER_BORDER_WIDTH / 100)\n",
    "\n",
    "    # 3. Create a new, larger image (the canvas) and fill it with white\n",
    "    # The new total size is the original size plus the border on both sides (left/right or top/bottom)\n",
    "    new_size = MARKER_SIZE + 2 * border_pixels\n",
    "    bordered_image = np.full((new_size, new_size), 255, dtype=np.uint8)\n",
    "\n",
    "    # 4. Copy the generated marker onto the center of the white canvas\n",
    "    # We calculate the region where the marker should be placed\n",
    "    start_point = border_pixels\n",
    "    end_point = border_pixels + MARKER_SIZE\n",
    "    bordered_image[start_point:end_point, start_point:end_point] = marker_image\n",
    "\n",
    "    # 5. Define the filename and save the new image\n",
    "    file_name = os.path.join(MARKER_FOLDER, f\"marker-{marker_id}.png\")\n",
    "    cv2.imwrite(file_name, bordered_image)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Generated {NUM_MARKERS} markers, {MARKER_SIZE}x{MARKER_SIZE} pixels with a {MARKER_BORDER_WIDTH}% white border.\")\n",
    "print(f\"Successfully saved markers to '{os.path.abspath(MARKER_FOLDER)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b2bfd-5b60-485a-8648-581ae87665ab",
   "metadata": {},
   "source": [
    "# Generate Chessboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844581b7-44f1-4e35-b850-9f805ac8bd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a 10x7 chessboard pattern...\n",
      "------------------------------\n",
      "Successfully saved chessboard pattern to 'C:\\Users\\kwiat\\Documents\\GitHub\\Unitree-G1-3D-position-tracking\\chessboard.png'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating a {CHESSBOARD_DIMENSIONS[0]}x{CHESSBOARD_DIMENSIONS[1]} chessboard pattern...\")\n",
    "\n",
    "# Calculate the total size of the image in pixels\n",
    "img_width = CHESSBOARD_DIMENSIONS[0] * CHESSBOARD_SQUARE_SIZE\n",
    "img_height = CHESSBOARD_DIMENSIONS[1] * CHESSBOARD_SQUARE_SIZE\n",
    "\n",
    "# Create a new blank image (3 channels for BGR color) and fill it with white\n",
    "# White in BGR is (255, 255, 255)\n",
    "chessboard = np.full((img_height, img_width, 3), 255, dtype=np.uint8)\n",
    "\n",
    "# Loop through each square of the board to draw the pattern\n",
    "for row in range(CHESSBOARD_DIMENSIONS[1]):\n",
    "    for col in range(CHESSBOARD_DIMENSIONS[0]):\n",
    "        # Determine if the square should be black or white\n",
    "        # If the sum of the row and column is an even number, color the square black\n",
    "        if (row + col) % 2 == 0:\n",
    "            # Calculate the top-left corner of the square\n",
    "            top_left_x = col * CHESSBOARD_SQUARE_SIZE\n",
    "            top_left_y = row * CHESSBOARD_SQUARE_SIZE\n",
    "            \n",
    "            # Calculate the bottom-right corner of the square\n",
    "            bottom_right_x = top_left_x + CHESSBOARD_SQUARE_SIZE\n",
    "            bottom_right_y = top_left_y + CHESSBOARD_SQUARE_SIZE\n",
    "            \n",
    "            # Draw a filled black rectangle on the image\n",
    "            # Color for black is (0, 0, 0)\n",
    "            cv2.rectangle(\n",
    "                chessboard, \n",
    "                (top_left_x, top_left_y), \n",
    "                (bottom_right_x, bottom_right_y), \n",
    "                (0, 0, 0), \n",
    "                -1  # A thickness of -1 fills the rectangle\n",
    "            )\n",
    "\n",
    "# Save the final generated image to a file\n",
    "print(\"-\" * 30)\n",
    "try:\n",
    "    cv2.imwrite(CHESSBOARD_FILENAME, chessboard)\n",
    "    print(f\"Successfully saved chessboard pattern to '{os.path.abspath(CHESSBOARD_FILENAME)}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: Could not save the image. {e}\")\n",
    "\n",
    "# Optional: Display the image in a window until a key is pressed\n",
    "cv2.imshow('Generated Chessboard', chessboard)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf96f18-e91c-484c-b6c5-41db27e70323",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2d0f28-2759-4cf3-8e4a-e8a55254a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_camera():\n",
    "    \"\"\"\n",
    "    Detects available cameras and prompts the user to select one.\n",
    "    Returns the selected camera index or None if no cameras are found.\n",
    "    \"\"\"\n",
    "    print(\"Detecting available cameras...\")\n",
    "    available_cameras = []\n",
    "    for i in range(5):\n",
    "        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)\n",
    "        if cap.isOpened():\n",
    "            available_cameras.append(i)\n",
    "            cap.release()\n",
    "\n",
    "    if not available_cameras:\n",
    "        print(\"Error: No cameras found.\")\n",
    "        return None\n",
    "    \n",
    "    if len(available_cameras) == 1:\n",
    "        print(f\"Only one camera found (index {available_cameras[0]}). Selecting it automatically.\")\n",
    "        return available_cameras[0]\n",
    "\n",
    "    print(\"Multiple cameras found. Please select one:\")\n",
    "    for index in available_cameras:\n",
    "        print(f\"- Enter '{index}' for camera {index}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Your choice: \"))\n",
    "            if choice in available_cameras:\n",
    "                return choice\n",
    "            else:\n",
    "                print(\"Invalid choice. Please select from the available indices.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5cc6a-fe84-4c28-ad52-fa719387c2b1",
   "metadata": {},
   "source": [
    "# Camera Distortion Correction Callibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3633b2d-9964-48e9-a603-ed927f70589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Camera Calibration...\n",
      "--> Looking for a 9x6 chessboard pattern.\n",
      "--> Press the [SPACE] bar to capture an image.\n",
      "--> You need at least 15 good images from different angles and distances.\n",
      "--> Press [c] to calibrate once you have enough images.\n",
      "--> Press [q] to quit.\n",
      "Detecting available cameras...\n",
      "Multiple cameras found. Please select one:\n",
      "- Enter '0' for camera 0\n",
      "- Enter '1' for camera 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 captured and saved to calibration-images\\calibration-image-0.png.\n",
      "Image 2 captured and saved to calibration-images\\calibration-image-1.png.\n",
      "Image 3 captured and saved to calibration-images\\calibration-image-2.png.\n",
      "Image 4 captured and saved to calibration-images\\calibration-image-3.png.\n",
      "Image 5 captured and saved to calibration-images\\calibration-image-4.png.\n",
      "Image 6 captured and saved to calibration-images\\calibration-image-5.png.\n",
      "Image 7 captured and saved to calibration-images\\calibration-image-6.png.\n",
      "Image 8 captured and saved to calibration-images\\calibration-image-7.png.\n",
      "Image 9 captured and saved to calibration-images\\calibration-image-8.png.\n",
      "Image 10 captured and saved to calibration-images\\calibration-image-9.png.\n",
      "Image 11 captured and saved to calibration-images\\calibration-image-10.png.\n",
      "Image 12 captured and saved to calibration-images\\calibration-image-11.png.\n",
      "Image 13 captured and saved to calibration-images\\calibration-image-12.png.\n",
      "Image 14 captured and saved to calibration-images\\calibration-image-13.png.\n",
      "Image 15 captured and saved to calibration-images\\calibration-image-14.png.\n",
      "Image 16 captured and saved to calibration-images\\calibration-image-15.png.\n",
      "Image 17 captured and saved to calibration-images\\calibration-image-16.png.\n",
      "Image 18 captured and saved to calibration-images\\calibration-image-17.png.\n",
      "Image 19 captured and saved to calibration-images\\calibration-image-18.png.\n",
      "Image 20 captured and saved to calibration-images\\calibration-image-19.png.\n",
      "\n",
      "Calibrating camera... this may take a moment.\n",
      "Calibration successful!\n",
      "Calibration data saved to 'calibration_data.json'\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# You need a chessboard pattern. The numbers here are the number of *internal* corners.\n",
    "# For a standard 9x6 board, you'd use (8, 5). For a 10x7 board, use (9, 6).\n",
    "chessboard_corners = (CHESSBOARD_DIMENSIONS[0] - 1, CHESSBOARD_DIMENSIONS[1] - 1)\n",
    "# The name of the file where calibration data will be saved.\n",
    "CALIBRATION_FILE = \"calibration_data.json\"\n",
    "# The folder where captured images will be saved.\n",
    "CALIBRATION_IMAGES_FOLDER = \"calibration-images\"\n",
    "\n",
    "# --- Main Calibration Logic ---\n",
    "print(\"Starting Camera Calibration...\")\n",
    "print(f\"--> Looking for a {chessboard_corners[0]}x{chessboard_corners[1]} chessboard pattern.\")\n",
    "print(\"--> Press the [SPACE] bar to capture an image.\")\n",
    "print(\"--> You need at least 15 good images from different angles and distances.\")\n",
    "print(\"--> Press [c] to calibrate once you have enough images.\")\n",
    "print(\"--> Press [q] to quit.\")\n",
    "\n",
    "# Create the output folder for images if it doesn't exist\n",
    "if not os.path.exists(CALIBRATION_IMAGES_FOLDER):\n",
    "    os.makedirs(CALIBRATION_IMAGES_FOLDER)\n",
    "    print(f\"Folder '{CALIBRATION_IMAGES_FOLDER}' created.\")\n",
    "\n",
    "# Termination criteria for the corner sub-pixel algorithm\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "objp = np.zeros((chessboard_corners[0] * chessboard_corners[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboard_corners[0], 0:chessboard_corners[1]].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# (Assuming the select_camera() function is defined elsewhere in your notebook)\n",
    "camera_index = select_camera() \n",
    "if camera_index is None:\n",
    "    raise SystemExit(\"No camera selected. Exiting.\")\n",
    "\n",
    "cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)\n",
    "\n",
    "# --- Set the camera resolution ---\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "images_captured = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Display the current frame\n",
    "    display_frame = frame.copy()\n",
    "    cv2.putText(display_frame, f\"Images Captured: {images_captured}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Calibration', display_frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord(' '): # Space bar to capture\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, chessboard_corners, None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            # Save the captured frame BEFORE drawing on it\n",
    "            image_filename = os.path.join(CALIBRATION_IMAGES_FOLDER, f\"calibration-image-{images_captured}.png\")\n",
    "            cv2.imwrite(image_filename, frame)\n",
    "\n",
    "            images_captured += 1\n",
    "            print(f\"Image {images_captured} captured and saved to {image_filename}.\")\n",
    "            \n",
    "            objpoints.append(objp)\n",
    "            \n",
    "            # Refine corner locations for better accuracy\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            \n",
    "            # Draw and display the corners on the frame for visualization\n",
    "            cv2.drawChessboardCorners(frame, chessboard_corners, corners2, ret)\n",
    "            cv2.imshow('Last Capture', frame)\n",
    "        else:\n",
    "            print(\"Could not find chessboard. Try a different angle.\")\n",
    "\n",
    "    elif key == ord('c') and images_captured >= 15:\n",
    "        print(\"\\nCalibrating camera... this may take a moment.\")\n",
    "        \n",
    "        # Perform camera calibration\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "        if ret:\n",
    "            print(\"Calibration successful!\")\n",
    "            # Create a dictionary to hold the calibration data\n",
    "            # Convert numpy arrays to lists to make them JSON serializable\n",
    "            calibration_data = {\n",
    "                'camera_matrix': mtx.tolist(),\n",
    "                'distortion_coefficients': dist.tolist()\n",
    "            }\n",
    "            \n",
    "            # Save the data to a JSON file\n",
    "            with open(CALIBRATION_FILE, 'w') as f:\n",
    "                json.dump(calibration_data, f, indent=4)\n",
    "                \n",
    "            print(f\"Calibration data saved to '{CALIBRATION_FILE}'\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Calibration failed. Please try again with more diverse images.\")\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "        try:\n",
    "            if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "        except cv2.error:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c4480-2adb-4914-a3fe-fa07dd3e73d3",
   "metadata": {},
   "source": [
    "# Live Webcam Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e4f89be-2b29-4a18-96e2-01f19d09197b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera calibration data loaded successfully.\n",
      "Detecting available cameras...\n",
      "Multiple cameras found. Please select one:\n",
      "- Enter '0' for camera 0\n",
      "- Enter '1' for camera 1\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream terminated. 'positions_history' is ready for animation.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_MARKERS = 50\n",
    "FRAME_WIDTH = 1920\n",
    "FRAME_HEIGHT = 1080\n",
    "# The file containing the camera calibration data\n",
    "CALIBRATION_FILE = \"calibration_data.json\"\n",
    "ARUCO_DICT = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "\n",
    "# --- Main Program ---\n",
    "\n",
    "# Step 1: Load Camera Calibration Data from JSON\n",
    "if not os.path.exists(CALIBRATION_FILE):\n",
    "    print(f\"Error: Calibration file '{CALIBRATION_FILE}' not found.\")\n",
    "    print(\"Please run the 'Camera Calibration Script' first.\")\n",
    "    mtx, dist = None, None\n",
    "else:\n",
    "    with open(CALIBRATION_FILE, 'r') as f:\n",
    "        calibration_data = json.load(f)\n",
    "        # Convert lists from JSON back to numpy arrays\n",
    "        mtx = np.array(calibration_data['camera_matrix'])\n",
    "        dist = np.array(calibration_data['distortion_coefficients'])\n",
    "    print(\"Camera calibration data loaded successfully.\")\n",
    "\n",
    "# Proceed only if calibration data was loaded\n",
    "if mtx is not None and dist is not None:\n",
    "    positions_history = []\n",
    "\n",
    "    # (Assuming the select_camera() function is defined elsewhere in your notebook)\n",
    "    camera_index = select_camera()\n",
    "    if camera_index is None:\n",
    "        raise SystemExit(\"No camera selected. Exiting.\")\n",
    "\n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open webcam at index {camera_index}\")\n",
    "\n",
    "    parameters = cv2.aruco.DetectorParameters()\n",
    "    parameters.cornerRefinementMethod = cv2.aruco.CORNER_REFINE_SUBPIX\n",
    "    detector = cv2.aruco.ArucoDetector(ARUCO_DICT, parameters)\n",
    "    \n",
    "    window_name = 'Live Undistorted Feed with Marker Logging'\n",
    "    h, w = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Step 2: Apply the distortion correction to the frame\n",
    "        undistorted_frame = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "        \n",
    "        # Crop the image to the valid region (removes black borders)\n",
    "        x, y, w_roi, h_roi = roi\n",
    "        undistorted_frame = undistorted_frame[y:y+h_roi, x:x+w_roi]\n",
    "\n",
    "        # --- Detection now runs on the corrected frame ---\n",
    "        frame_positions = [None] * NUM_MARKERS\n",
    "        gray = cv2.cvtColor(undistorted_frame, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, rejected = detector.detectMarkers(gray)\n",
    "\n",
    "        if ids is not None:\n",
    "            for i, marker_id in enumerate(ids.flatten()):\n",
    "                if 0 <= marker_id < NUM_MARKERS:\n",
    "                    marker_corners = corners[i].reshape((4, 2))\n",
    "                    cx = int(np.mean(marker_corners[:, 0]))\n",
    "                    cy = int(np.mean(marker_corners[:, 1]))\n",
    "                    frame_positions[marker_id] = (cx, cy)\n",
    "                    \n",
    "                    cv2.polylines(undistorted_frame, [marker_corners.astype(np.int32)], True, (0, 255, 0), 2)\n",
    "                    cv2.circle(undistorted_frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "                    cv2.putText(undistorted_frame, str(marker_id), (int(marker_corners[0, 0]), int(marker_corners[0, 1]) - 15),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        positions_history.append(frame_positions)\n",
    "        cv2.imshow(window_name, undistorted_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break\n",
    "        except cv2.error:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Stream terminated. 'positions_history' is ready for animation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c5aa1-415d-4ec9-aa05-c45f6596bf30",
   "metadata": {},
   "source": [
    "# Position tracking 2D visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c31acf-39be-4e56-a1f0-b4192d11ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Configure matplotlib for Jupyter notebook rendering\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "# A higher DPI gives a clearer animation. If you hit the size limit again, you can lower this value.\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Check if the position data exists and is not empty\n",
    "if 'positions_history' not in locals() or not positions_history:\n",
    "    print(\"Error: The 'positions_history' data was not found or is empty.\")\n",
    "    print(\"Please run the previous script cell to capture marker data first.\")\n",
    "else:\n",
    "    # --- Animation Setup ---\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.set_xlim(0, FRAME_WIDTH)\n",
    "    ax.set_ylim(0, FRAME_HEIGHT)\n",
    "    \n",
    "    # Invert the Y axis to match image coordinates (0,0 at top-left)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # --- EFFICIENT ARTIST INITIALIZATION ---\n",
    "    # Initialize the scatter plot for the marker centers\n",
    "    scatter = ax.scatter([], [], s=50, c='red', zorder=3)\n",
    "    \n",
    "    # Create a pool of text artists, one for each marker.\n",
    "    # They are initially invisible and will be updated each frame.\n",
    "    texts = []\n",
    "    for i in range(NUM_MARKERS):\n",
    "        text = ax.text(0, 0, str(i), color='blue', fontsize=9, visible=False, zorder=4)\n",
    "        texts.append(text)\n",
    "        \n",
    "    # Initialize a single title object that we can update efficiently\n",
    "    title = ax.set_title(\"Animation of Detected Marker Positions\")\n",
    "\n",
    "    # --- Animation Update Function ---\n",
    "    def update(frame_index):\n",
    "        #print(f\"frame {frame_index}\") # You can uncomment this for debugging\n",
    "        current_positions = positions_history[frame_index]\n",
    "        \n",
    "        visible_coords = []\n",
    "        \n",
    "        # Loop through all possible markers and update their text artists\n",
    "        for marker_id, pos in enumerate(current_positions):\n",
    "            text_artist = texts[marker_id]\n",
    "            if pos is not None:\n",
    "                visible_coords.append(pos)\n",
    "                text_artist.set_position((pos[0], pos[1] - 20))\n",
    "                text_artist.set_visible(True)\n",
    "            else:\n",
    "                text_artist.set_visible(False)\n",
    "        \n",
    "        if visible_coords:\n",
    "            scatter.set_offsets(np.array(visible_coords))\n",
    "        else:\n",
    "            scatter.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "        title.set_text(f\"Animation of Detected Marker Positions (Frame: {frame_index + 1}/{len(positions_history)})\")\n",
    "\n",
    "        # Return all artists that could have been modified\n",
    "        return [scatter, title] + texts\n",
    "\n",
    "    # --- Create and Display the Animation ---\n",
    "    ani = animation.FuncAnimation(\n",
    "        fig=fig, \n",
    "        func=update, \n",
    "        frames=len(positions_history), \n",
    "        interval=50, \n",
    "        blit=False \n",
    "    )\n",
    "\n",
    "    # --- Display the Animation ---\n",
    "    # FIX: Using an explicit display call with HTML can be more reliable\n",
    "    # in some Jupyter environments than relying on the default display.\n",
    "    plt.close(fig) # Prevent the initial static plot from showing up\n",
    "    display(HTML(ani.to_jshtml()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c702f6-c14b-434a-aade-e5bd86230ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
