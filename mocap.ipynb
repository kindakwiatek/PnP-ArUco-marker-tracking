{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Capture System Controller\n",
    "\n",
    "This Jupyter Notebook is the complete control panel for the ArUco marker-based motion capture system. This notebook is divided into four main parts:\n",
    "\n",
    "1.  **Asset Generation:** Create printable ArUco markers and a chessboard pattern for calibration.\n",
    "2.  **Local Testing:** Use a local webcam to test distortion calibration and marker detection without the need for remote servers.\n",
    "3.  **Remote System Management:** Manage the Raspberry Pi servers, including rebooting and performing headless distortion calibration.\n",
    "4.  **Live 3D Tracking:** Launch the real-time 3D visualization of the tracked markers and camera poses.\n",
    "\n",
    "---\n",
    "### OpenCV Documentation\n",
    "- **Camera Calibration and 3D reconstruction:** https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html\n",
    "- **Detection of ArUco Markers:** https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Imports and Configuration\n",
    "\n",
    "**Instructions:**\n",
    "1. Before running, ensure you have created and filled out a `pi_settings.conf` file inside the `server/bootfs/` directory, based on the provided template.\n",
    "2. Run the following cells to import all necessary libraries and load your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports and Setup ---\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import socket\n",
    "import json\n",
    "import logging\n",
    "import paramiko\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scp import SCPClient\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QWidget, QVBoxLayout, QStatusBar\n",
    "from PyQt5.QtCore import QThread, QObject, pyqtSignal, pyqtSlot\n",
    "import pyqtgraph.opengl as gl\n",
    "from pyqtgraph.opengl import GLMeshItem\n",
    "from pyqtgraph.Qt import QtGui\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Add project root to path to allow importing config\n",
    "if '.' not in sys.path:\n",
    "    sys.path.insert(0, '.')\n",
    "import config\n",
    "\n",
    "# --- Logging Setup ---\n",
    "LOG_DIR = 'client_logs'\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(os.path.join(LOG_DIR, 'mocap_controller.log')),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load SSH Credentials from pi_settings.conf ---\n",
    "SSH_USERNAME, SSH_PASSWORD = None, None\n",
    "def parse_conf_file(filepath):\n",
    "    \"\"\"Parses a shell-style .conf file and returns a dictionary.\"\"\"\n",
    "    creds = {}\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    match = re.match(r'^(\\w+)=\"(.*?)\"$', line)\n",
    "                    if match:\n",
    "                        key, value = match.groups()\n",
    "                        creds[key] = value\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "    return creds\n",
    "\n",
    "conf_path = os.path.join('server', 'bootfs', 'pi_settings.conf')\n",
    "pi_config = parse_conf_file(conf_path)\n",
    "\n",
    "if pi_config and 'SSH_USERNAME' in pi_config and 'SSH_PASSWORD' in pi_config:\n",
    "    SSH_USERNAME = pi_config['SSH_USERNAME']\n",
    "    SSH_PASSWORD = pi_config['SSH_PASSWORD']\n",
    "    logging.info(f\"Successfully loaded credentials from {conf_path}.\")\n",
    "    if SSH_USERNAME == \"your_secure_username\":\n",
    "        logging.warning(\"Using default username. Please update 'pi_settings.conf' with your credentials.\")\n",
    "else:\n",
    "    logging.error(f\"Could not load credentials. Please create '{conf_path}' from the template.\")\n",
    "\n",
    "logging.info(\"Motion capture controller notebook initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Asset Generation\n",
    "\n",
    "Use the following cells to generate the physical assets required for calibration and tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Generate ArUco Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_aruco_markers():\n",
    "    \"\"\"Generates and saves ArUco marker images based on settings in config.py.\"\"\"\n",
    "    os.makedirs(config.MARKER_FOLDER, exist_ok=True)\n",
    "    logging.info(f\"Generating {config.NUM_MARKERS} markers...\")\n",
    "\n",
    "    for marker_id in range(config.NUM_MARKERS):\n",
    "        marker_image = cv2.aruco.generateImageMarker(\n",
    "            config.ARUCO_DICT, marker_id, config.MARKER_SIZE_PX\n",
    "        )\n",
    "        border_pixels = int(config.MARKER_SIZE_PX * config.MARKER_BORDER_PERCENT / 100)\n",
    "        new_size = config.MARKER_SIZE_PX + 2 * border_pixels\n",
    "        bordered_image = np.full((new_size, new_size), 255, dtype=np.uint8)\n",
    "        start = border_pixels\n",
    "        end = border_pixels + config.MARKER_SIZE_PX\n",
    "        bordered_image[start:end, start:end] = marker_image\n",
    "        file_name = os.path.join(config.MARKER_FOLDER, f\"marker_{marker_id}.png\")\n",
    "        cv2.imwrite(file_name, bordered_image)\n",
    "\n",
    "    logging.info(f\"Generated {config.NUM_MARKERS} markers and saved to '{os.path.abspath(config.MARKER_FOLDER)}'.\")\n",
    "\n",
    "# Run the generation function\n",
    "generate_aruco_markers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Generate Chessboard Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chessboard():\n",
    "    \"\"\"Generates and saves a chessboard image based on settings in config.py.\"\"\"\n",
    "    # Ensure the parent directory exists before saving the file\n",
    "    os.makedirs(os.path.dirname(config.CHESSBOARD_FILENAME), exist_ok=True)\n",
    "    logging.info(f\"Generating a {config.CHESSBOARD_SQUARES[0]}x{config.CHESSBOARD_SQUARES[1]} chessboard...\")\n",
    "    \n",
    "    img_width = config.CHESSBOARD_SQUARES[0] * config.CHESSBOARD_SQUARE_SIZE_PX\n",
    "    img_height = config.CHESSBOARD_SQUARES[1] * config.CHESSBOARD_SQUARE_SIZE_PX\n",
    "    chessboard = np.full((img_height, img_width, 3), 255, dtype=np.uint8)\n",
    "\n",
    "    for row in range(config.CHESSBOARD_SQUARES[1]):\n",
    "        for col in range(config.CHESSBOARD_SQUARES[0]):\n",
    "            if (row + col) % 2 == 0:\n",
    "                top_left_x = col * config.CHESSBOARD_SQUARE_SIZE_PX\n",
    "                top_left_y = row * config.CHESSBOARD_SQUARE_SIZE_PX\n",
    "                bottom_right_x = top_left_x + config.CHESSBOARD_SQUARE_SIZE_PX\n",
    "                bottom_right_y = top_left_y + config.CHESSBOARD_SQUARE_SIZE_PX\n",
    "                cv2.rectangle(\n",
    "                    chessboard, \n",
    "                    (top_left_x, top_left_y), \n",
    "                    (bottom_right_x, bottom_right_y), \n",
    "                    (0, 0, 0), \n",
    "                    -1\n",
    "                )\n",
    "\n",
    "    try:\n",
    "        cv2.imwrite(config.CHESSBOARD_FILENAME, chessboard)\n",
    "        logging.info(f\"Successfully saved chessboard to '{os.path.abspath(config.CHESSBOARD_FILENAME)}'\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Could not save the image: {e}\")\n",
    "\n",
    "# Run the generation function\n",
    "generate_chessboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Local Testing\n",
    "\n",
    "Use this section to test camera functionality and algorithms on your local machine with a standard webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Helper Function: Select a Local Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_local_camera():\n",
    "    \"\"\"Detects available local cameras and prompts the user to select one.\"\"\"\n",
    "    logging.info(\"Detecting available local cameras...\")\n",
    "    available_cameras = []\n",
    "    # Check first 5 indices, which is usually sufficient\n",
    "    for i in range(5):\n",
    "        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)\n",
    "        if cap.isOpened():\n",
    "            available_cameras.append(i)\n",
    "            cap.release()\n",
    "\n",
    "    if not available_cameras:\n",
    "        logging.error(\"No local cameras found.\")\n",
    "        return None\n",
    "    \n",
    "    if len(available_cameras) == 1:\n",
    "        logging.info(f\"Only one camera found (index {available_cameras[0]}). Selecting automatically.\")\n",
    "        return available_cameras[0]\n",
    "\n",
    "    print(\"Multiple cameras found. Please select one:\")\n",
    "    for index in available_cameras:\n",
    "        print(f\"- Enter '{index}' for camera {index}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = int(input(\"Your choice: \"))\n",
    "            if choice in available_cameras:\n",
    "                return choice\n",
    "            else:\n",
    "                print(\"Invalid choice. Please select from the available indices.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Interactively Calibrate a Local Camera\n",
    "\n",
    "Run this cell to open a live camera feed. Point it at your printed chessboard from different angles and press the spacebar to capture images. Once you have at least 15 images, press 'c' to perform the calibration. The results will be saved to `distortion_calibration.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local_calibration():\n",
    "    \"\"\"Runs an interactive calibration process using a local webcam.\"\"\"\n",
    "    os.makedirs(config.DISTORTION_IMAGES_FOLDER, exist_ok=True)\n",
    "    logging.info(f\"Starting Local Camera Calibration... looking for a {config.CHESSBOARD_DIMENSIONS} pattern.\")\n",
    "    print(\"--> Press [SPACE] to capture. You need at least 15 images.\")\n",
    "    print(\"--> Press [c] to calibrate after capturing images.\")\n",
    "    print(\"--> Press [q] to quit.\")\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    objp = np.zeros((config.CHESSBOARD_DIMENSIONS[0] * config.CHESSBOARD_DIMENSIONS[1], 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:config.CHESSBOARD_DIMENSIONS[0], 0:config.CHESSBOARD_DIMENSIONS[1]].T.reshape(-1,2)\n",
    "\n",
    "    objpoints, imgpoints = [], []\n",
    "    images_captured = 0\n",
    "\n",
    "    camera_index = select_local_camera()\n",
    "    if camera_index is None: return\n",
    "\n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, config.FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config.FRAME_HEIGHT)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Cannot open webcam.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "        cv2.putText(display_frame, f\"Images Captured: {images_captured}\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow('Local Calibration', display_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(' '):\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, config.CHESSBOARD_DIMENSIONS, None)\n",
    "            if ret:\n",
    "                img_path = os.path.join(config.DISTORTION_IMAGES_FOLDER, f\"local_cal_{images_captured}.png\")\n",
    "                cv2.imwrite(img_path, frame)\n",
    "                images_captured += 1\n",
    "                logging.info(f\"Image {images_captured} captured.\")\n",
    "                objpoints.append(objp)\n",
    "                corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)\n",
    "                imgpoints.append(corners2)\n",
    "            else:\n",
    "                logging.warning(\"Chessboard not found. Try a different angle.\")\n",
    "        elif key == ord('c') and images_captured >= 15:\n",
    "            logging.info(\"Calibrating camera... this may take a moment.\")\n",
    "            gray_shape = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).shape[::-1]\n",
    "            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray_shape, None, None)\n",
    "            if ret:\n",
    "                calibration_data = {'camera_matrix': mtx.tolist(), 'distortion_coefficients': dist.tolist()}\n",
    "                with open(config.DISTORTION_DATA_FILE, 'w') as f:\n",
    "                    json.dump(calibration_data, f, indent=4)\n",
    "                logging.info(f\"Calibration successful! Data saved to '{config.DISTORTION_DATA_FILE}'\")\n",
    "                break\n",
    "            else:\n",
    "                logging.error(\"Calibration failed. Please try again.\")\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the local calibration\n",
    "run_local_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Test Local Marker Detection\n",
    "\n",
    "Run this cell to open a live, undistorted feed from your local webcam. It will detect and draw outlines around any visible ArUco markers. This is useful for verifying your camera and lighting conditions before deploying to the Raspberry Pis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local_detection():\n",
    "    \"\"\"Runs a live marker detection test using a local webcam and existing calibration data.\"\"\"\n",
    "    try:\n",
    "        with open(config.DISTORTION_DATA_FILE, 'r') as f:\n",
    "            calib_data = json.load(f)\n",
    "        mtx = np.array(calib_data['camera_matrix'])\n",
    "        dist = np.array(calib_data['distortion_coefficients'])\n",
    "        logging.info(\"Local camera calibration data loaded.\")\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"'{config.DISTORTION_DATA_FILE}' not found. Please run local calibration first.\")\n",
    "        return\n",
    "\n",
    "    camera_index = select_local_camera()\n",
    "    if camera_index is None: return\n",
    "\n",
    "    cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, config.FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, config.FRAME_HEIGHT)\n",
    "    if not cap.isOpened():\n",
    "        logging.error(\"Cannot open webcam.\")\n",
    "        return\n",
    "\n",
    "    detector = cv2.aruco.ArucoDetector(config.ARUCO_DICT, cv2.aruco.DetectorParameters())\n",
    "    h, w = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        undistorted = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "        x, y, w_roi, h_roi = roi\n",
    "        undistorted = undistorted[y:y+h_roi, x:x+w_roi]\n",
    "        \n",
    "        gray = cv2.cvtColor(undistorted, cv2.COLOR_BGR2GRAY)\n",
    "        corners, ids, _ = detector.detectMarkers(gray)\n",
    "\n",
    "        if ids is not None:\n",
    "            cv2.aruco.drawDetectedMarkers(undistorted, corners, ids)\n",
    "        \n",
    "        cv2.imshow('Local Marker Detection Test', undistorted)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the test\n",
    "test_local_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Remote System Management\n",
    "\n",
    "This section contains tools for managing the Raspberry Pi servers over the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Remotely Reboot All Servers\n",
    "\n",
    "Run the cell below to send a `sudo reboot` command to all servers listed in `config.py` simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssh_command(hostname, username, password, command):\n",
    "    \"\"\"Executes a command on a remote host via SSH.\"\"\"\n",
    "    client = paramiko.SSHClient()\n",
    "    client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    try:\n",
    "        logging.info(f\"[{hostname}] Connecting...\")\n",
    "        client.connect(hostname, username=username, password=password, timeout=10)\n",
    "        logging.info(f\"[{hostname}] Connected. Sending command: '{command}'\")\n",
    "        stdin, stdout, stderr = client.exec_command(command)\n",
    "        error = stderr.read().decode()\n",
    "        if error and \"closed by remote host\" not in error:\n",
    "            logging.error(f\"[{hostname}] Error: {error.strip()}\")\n",
    "        else:\n",
    "            logging.info(f\"[{hostname}] Command sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[{hostname}] Failed to connect or execute command: {e}\")\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "def remote_server_reboot():\n",
    "    \"\"\"Initiates the remote reboot command for all servers.\"\"\"\n",
    "    if not SSH_USERNAME or not SSH_PASSWORD or SSH_USERNAME == \"your_secure_username\":\n",
    "        logging.error(\"SSH credentials not configured. Set them in 'server/bootfs/pi_settings.conf'.\")\n",
    "        return\n",
    "    command_to_run = \"sudo reboot\"\n",
    "    threads = []\n",
    "    logging.info(f\"Preparing to send 'reboot' command to all servers...\")\n",
    "    for host in config.SERVER_HOSTS:\n",
    "        thread = threading.Thread(\n",
    "            target=ssh_command,\n",
    "            args=(host, SSH_USERNAME, SSH_PASSWORD, command_to_run)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    logging.info(\"Remote reboot command finished for all servers.\")\n",
    "\n",
    "# To reboot all servers, uncomment and run the line below\n",
    "# remote_server_reboot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Headless Distortion Calibration\n",
    "\n",
    "This section allows you to perform the one-time camera distortion calibration for a single Raspberry Pi entirely over the network.\n",
    "\n",
    "**Instructions:**\n",
    "1. Set the `TARGET_HOSTNAME` to the Pi you want to calibrate.\n",
    "2. Run the setup cell.\n",
    "3. Position the chessboard pattern in front of the target camera.\n",
    "4. Run the \"Capture Image\" cell repeatedly, repositioning the chessboard each time. Aim for at least 15 successful captures.\n",
    "5. Once you have enough images, run the \"Perform Calibration & Download\" cell. This will create/update the `distortion_calibration.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set the hostname of the Pi you want to calibrate\n",
    "TARGET_HOSTNAME = \"pi-mocap-1.local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Run this cell to define the CalibrationController class\n",
    "class CalibrationController:\n",
    "    \"\"\"Manages an SSH connection to a Pi for calibration tasks.\"\"\"\n",
    "    def __init__(self, hostname):\n",
    "        self.hostname = hostname\n",
    "        if not SSH_USERNAME or not SSH_PASSWORD:\n",
    "            raise ValueError(\"SSH Credentials not loaded from pi_settings.conf\")\n",
    "        self.username = SSH_USERNAME\n",
    "        self.password = SSH_PASSWORD\n",
    "        self.ssh_client = None\n",
    "        self.repo_dir = f\"/home/{self.username}/PnP-ArUco-marker-tracking\"\n",
    "\n",
    "    def connect(self):\n",
    "        logging.info(f\"--> Connecting to {self.hostname} for calibration...\")\n",
    "        try:\n",
    "            self.ssh_client = paramiko.SSHClient()\n",
    "            self.ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "            self.ssh_client.connect(self.hostname, username=self.username, password=self.password, timeout=15)\n",
    "            logging.info(\"--> Connection successful.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error connecting to {self.hostname}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def run_remote_command(self, command, timeout=30):\n",
    "        if not self.ssh_client: return False, \"\", \"Not connected\"\n",
    "        logging.info(f\"--> Executing: {command}\")\n",
    "        _, stdout, stderr = self.ssh_client.exec_command(command, timeout=timeout)\n",
    "        exit_status = stdout.channel.recv_exit_status()\n",
    "        out, err = stdout.read().decode().strip(), stderr.read().decode().strip()\n",
    "        if out: logging.info(f\"[{self.hostname} STDOUT]:\\n{out}\")\n",
    "        if err: logging.error(f\"[{self.hostname} STDERR]:\\n{err}\")\n",
    "        return exit_status == 0, out, err\n",
    "\n",
    "    def capture_image(self):\n",
    "        script_path = os.path.join(self.repo_dir, \"server/distortion_calibration.py\")\n",
    "        command = f\"python3 {script_path} --capture --host {self.hostname.replace('.local', '')}\"\n",
    "        return self.run_remote_command(command)\n",
    "\n",
    "    def perform_calibration(self):\n",
    "        script_path = os.path.join(self.repo_dir, \"server/distortion_calibration.py\")\n",
    "        command = f\"python3 {script_path} --calibrate\"\n",
    "        return self.run_remote_command(command, timeout=90)\n",
    "\n",
    "    def download_calibration_file(self):\n",
    "        remote_path = os.path.join(self.repo_dir, config.DISTORTION_DATA_FILE)\n",
    "        local_path = config.DISTORTION_DATA_FILE\n",
    "        logging.info(f\"--> Attempting to download '{remote_path}' to local '{local_path}'...\")\n",
    "        try:\n",
    "            with SCPClient(self.ssh_client.get_transport()) as scp:\n",
    "                scp.get(remote_path, local_path)\n",
    "            logging.info(f\"--> Success! Calibration file saved to '{os.path.abspath(local_path)}'\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error downloading file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def close(self):\n",
    "        if self.ssh_client:\n",
    "            self.ssh_client.close()\n",
    "            logging.info(\"--> Calibration connection closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Capture Remote Image (Run this cell multiple times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = CalibrationController(TARGET_HOSTNAME)\n",
    "if controller.connect():\n",
    "    try:\n",
    "        controller.capture_image()\n",
    "    finally:\n",
    "        controller.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform Remote Calibration & Download (Run this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = CalibrationController(TARGET_HOSTNAME)\n",
    "if controller.connect():\n",
    "    try:\n",
    "        success, _, _ = controller.perform_calibration()\n",
    "        if success:\n",
    "            time.sleep(1)\n",
    "            controller.download_calibration_file()\n",
    "    finally:\n",
    "        controller.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Live 3D Tracking & Visualization\n",
    "\n",
    "This section launches the main application for tracking markers in 3D. It connects to all servers, performs continuous camera pose estimation, and displays the results in a real-time 3D plot.\n",
    "\n",
    "**Instructions:**\n",
    "1. Ensure the `distortion_calibration.json` file exists in the project root (by running the calibration step above).\n",
    "2. Run the cell below. A separate PyQt5 window will open with the 3D visualization.\n",
    "3. To stop the application, simply close the visualization window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global Data Structures ---\n",
    "live_marker_data = {}  # {marker_id: {host: (x, y), ...}}\n",
    "camera_poses = {}      # {host: {'rvec': ..., 'tvec': ..., 'time': ...}}\n",
    "tracked_points_3d = {} # {marker_id: [x, y, z]}\n",
    "data_lock = threading.Lock()\n",
    "\n",
    "# --- Class Definitions for Visualization ---\n",
    "class CameraClient(threading.Thread):\n",
    "    \"\"\"Manages the connection and data flow for a single Pi server.\"\"\"\n",
    "    def __init__(self, host, port):\n",
    "        super().__init__()\n",
    "        self.host, self.port = host, port\n",
    "        self.sock, self.is_connected = None, False\n",
    "        self.stop_event = threading.Event()\n",
    "        self.daemon = True\n",
    "\n",
    "    def run(self):\n",
    "        while not self.stop_event.is_set():\n",
    "            try:\n",
    "                logging.info(f\"[{self.host}] Attempting to connect...\")\n",
    "                self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "                self.sock.settimeout(5)\n",
    "                self.sock.connect((self.host, self.port))\n",
    "                self.is_connected = True\n",
    "                logging.info(f\"[{self.host}] Connection successful.\")\n",
    "                self.listen_for_data()\n",
    "            except (ConnectionRefusedError, socket.gaierror, socket.timeout) as e:\n",
    "                logging.warning(f\"[{self.host}] Connection failed: {e}. Retrying in 5s.\")\n",
    "                self.is_connected = False\n",
    "                time.sleep(5)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"[{self.host}] Unhandled exception: {e}\")\n",
    "                self.is_connected = False\n",
    "                time.sleep(5)\n",
    "\n",
    "    def listen_for_data(self):\n",
    "        f = self.sock.makefile('r')\n",
    "        while not self.stop_event.is_set():\n",
    "            try:\n",
    "                line = f.readline()\n",
    "                if not line: break\n",
    "                self._process_server_message(line.strip())\n",
    "            except (IOError, ConnectionResetError): break\n",
    "        self.is_connected = False\n",
    "        logging.info(f\"[{self.host}] Disconnected.\")\n",
    "\n",
    "    def _process_server_message(self, message):\n",
    "        global live_marker_data\n",
    "        try:\n",
    "            marker_positions = json.loads(message)\n",
    "            with data_lock:\n",
    "                for marker in marker_positions:\n",
    "                    marker_id = marker['id']\n",
    "                    if marker_id not in live_marker_data: live_marker_data[marker_id] = {}\n",
    "                    live_marker_data[marker_id][self.host] = tuple(marker['pos'])\n",
    "        except json.JSONDecodeError: pass\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_event.set()\n",
    "        if self.sock:\n",
    "            try: self.sock.shutdown(socket.SHUT_RDWR)\n",
    "            except OSError: pass\n",
    "            self.sock.close()\n",
    "\n",
    "class ProcessingWorker(QObject):\n",
    "    \"\"\"Worker that runs PnP and triangulation in a separate thread.\"\"\"\n",
    "    new_data = pyqtSignal()\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stop_event = threading.Event()\n",
    "        self.camera_matrix, self.dist_coeffs = None, None\n",
    "        self.pnp_object_points, self.pnp_marker_ids = None, None\n",
    "\n",
    "    def run(self):\n",
    "        if not self.load_calibration_data(): return\n",
    "        while not self.stop_event.is_set():\n",
    "            self.update_camera_poses()\n",
    "            self.triangulate_tracked_points()\n",
    "            self.new_data.emit()\n",
    "            time.sleep(0.05)\n",
    "        logging.info(\"Processing worker stopped.\")\n",
    "\n",
    "    def load_calibration_data(self):\n",
    "        try:\n",
    "            with open(config.DISTORTION_DATA_FILE, 'r') as f:\n",
    "                calib_data = json.load(f)\n",
    "                self.camera_matrix = np.array(calib_data['camera_matrix'])\n",
    "                self.dist_coeffs = np.array(calib_data['distortion_coefficients'])\n",
    "            self.pnp_marker_ids = list(config.PNP_MARKER_WORLD_COORDINATES.keys())\n",
    "            self.pnp_object_points = np.array([config.PNP_MARKER_WORLD_COORDINATES[i] for i in self.pnp_marker_ids], dtype=np.float32)\n",
    "            logging.info(\"Distortion calibration and PnP data loaded.\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"'{config.DISTORTION_DATA_FILE}' not found. Run calibration first.\")\n",
    "            return False\n",
    "\n",
    "    def update_camera_poses(self):\n",
    "        global camera_poses\n",
    "        with data_lock: current_data = {mid: obs.copy() for mid, obs in live_marker_data.items()}\n",
    "        for host in config.SERVER_HOSTS:\n",
    "            image_points, object_points = [], []\n",
    "            for marker_id in self.pnp_marker_ids:\n",
    "                if marker_id in current_data and host in current_data[marker_id]:\n",
    "                    image_points.append(current_data[marker_id][host])\n",
    "                    object_points.append(config.PNP_MARKER_WORLD_COORDINATES[marker_id])\n",
    "            if len(image_points) >= 4:\n",
    "                success, rvec, tvec = cv2.solvePnP(np.array(object_points, dtype=np.float32), np.array(image_points, dtype=np.float32), self.camera_matrix, self.dist_coeffs)\n",
    "                if success:\n",
    "                    with data_lock: camera_poses[host] = {'rvec': rvec, 'tvec': tvec, 'time': time.time()}\n",
    "\n",
    "    def triangulate_tracked_points(self):\n",
    "        global tracked_points_3d\n",
    "        with data_lock:\n",
    "            valid_poses = {h: p for h, p in camera_poses.items() if time.time() - p['time'] < 2.0}\n",
    "            if len(valid_poses) < 2:\n",
    "                tracked_points_3d = {}\n",
    "                return\n",
    "            current_data = {mid: obs.copy() for mid, obs in live_marker_data.items()}\n",
    "            current_tracked = {}\n",
    "            for marker_id, observations in current_data.items():\n",
    "                if marker_id in self.pnp_marker_ids: continue\n",
    "                valid_observations = {h: p for h, p in observations.items() if h in valid_poses}\n",
    "                if len(valid_observations) < 2: continue\n",
    "                pos_3d = self.triangulate_point(valid_observations, valid_poses)\n",
    "                if pos_3d is not None: current_tracked[marker_id] = pos_3d\n",
    "            tracked_points_3d = current_tracked\n",
    "\n",
    "    def triangulate_point(self, observations, poses):\n",
    "        proj_matrices, points_2d = [], []\n",
    "        for host, point_2d in list(observations.items())[:2]:\n",
    "            pose = poses[host]\n",
    "            R, _ = cv2.Rodrigues(pose['rvec'])\n",
    "            extrinsic_matrix = np.hstack((R, pose['tvec']))\n",
    "            proj_matrix = self.camera_matrix @ extrinsic_matrix\n",
    "            proj_matrices.append(proj_matrix)\n",
    "            points_2d.append(np.array(point_2d, dtype=np.float32))\n",
    "        points1, points2 = points_2d[0].reshape(2, 1), points_2d[1].reshape(2, 1)\n",
    "        points_4d_hom = cv2.triangulatePoints(proj_matrices[0], proj_matrices[1], points1, points2)\n",
    "        return (points_4d_hom[:3] / points_4d_hom[3]).flatten() if points_4d_hom[3] != 0 else None\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_event.set()\n",
    "\n",
    "class VisualizationWindow(QMainWindow):\n",
    "    \"\"\"The main application window with the 3D plot.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"Real-Time 3D Motion Capture Viewer\")\n",
    "        self.setGeometry(100, 100, 1200, 800)\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        layout = QVBoxLayout(central_widget)\n",
    "        self.view = gl.GLViewWidget()\n",
    "        layout.addWidget(self.view)\n",
    "        self.view.setCameraPosition(distance=200, elevation=30, azimuth=45)\n",
    "        grid = gl.GLGridItem(); grid.scale(20, 20, 1); self.view.addItem(grid)\n",
    "        ref_coords = np.array(list(config.PNP_MARKER_WORLD_COORDINATES.values()))\n",
    "        self.ref_points = gl.GLScatterPlotItem(pos=ref_coords, color=(1, 0, 0, 1), size=10, pxMode=True)\n",
    "        self.view.addItem(self.ref_points)\n",
    "        self.live_points = gl.GLScatterPlotItem(pos=np.empty((0,3)), color=(0, 0, 1, 1), size=15, pxMode=True)\n",
    "        self.view.addItem(self.live_points)\n",
    "        self.camera_meshes, self.camera_mesh_template = {}, self.create_camera_pyramid_mesh()\n",
    "        for host in config.SERVER_HOSTS:\n",
    "            mesh_item = GLMeshItem(meshdata=self.camera_mesh_template, smooth=False, drawEdges=True, edgeColor=(1,1,0,1), shader='balloon')\n",
    "            self.camera_meshes[host] = mesh_item\n",
    "            self.view.addItem(mesh_item)\n",
    "        self.statusBar = QStatusBar(); self.setStatusBar(self.statusBar)\n",
    "\n",
    "    def create_camera_pyramid_mesh(self):\n",
    "        verts = np.array([[0,0,0], [-5,-4,10], [5,-4,10], [5,4,10], [-5,4,10]])\n",
    "        faces = np.array([[0,1,2], [0,2,3], [0,3,4], [0,4,1], [1,2,3], [1,3,4]])\n",
    "        return gl.MeshData(vertexes=verts, faces=faces)\n",
    "\n",
    "    @pyqtSlot()\n",
    "    def update_plot(self):\n",
    "        with data_lock:\n",
    "            if tracked_points_3d:\n",
    "                self.live_points.setData(pos=np.array(list(tracked_points_3d.values())))\n",
    "            else:\n",
    "                self.live_points.setData(pos=np.empty((0,3)))\n",
    "            calibrated_cams = 0\n",
    "            for host, pose in camera_poses.items():\n",
    "                if time.time() - pose.get('time', 0) < 2.0:\n",
    "                    calibrated_cams += 1\n",
    "                    R, _ = cv2.Rodrigues(pose['rvec'])\n",
    "                    # Create a 4x4 transformation matrix from rotation and translation\n",
    "                    transform = np.eye(4)\n",
    "                    transform[:3, :3] = R.T # Transpose of R is the inverse for rotation matrix\n",
    "                    transform[:3, 3] = -R.T @ pose['tvec'].flatten()\n",
    "                    # Invert camera transform to get world placement\n",
    "                    cam_transform = np.linalg.inv(transform)\n",
    "                    \n",
    "                    # Convert to PyQtGraph's QMatrix4x4 and apply\n",
    "                    q_transform = QtGui.QMatrix4x4(cam_transform.T.flatten().tolist())\n",
    "                    self.camera_meshes[host].setTransform(q_transform)\n",
    "                    self.camera_meshes[host].setVisible(True)\n",
    "                else:\n",
    "                    self.camera_meshes[host].setVisible(False)\n",
    "        self.statusBar.showMessage(f\"Tracking {len(tracked_points_3d)} markers | Calibrated Cameras: {calibrated_cams}/{len(config.SERVER_HOSTS)}\")\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        logging.info(\"Visualization window closed by user. Initiating cleanup.\")\n",
    "        QApplication.instance().quit() # Trigger the application to quit\n",
    "        event.accept()\n",
    "\n",
    "# --- Main Execution Logic ---\n",
    "def run_visualization():\n",
    "    if not QApplication.instance():\n",
    "        app = QApplication(sys.argv)\n",
    "    else:\n",
    "        app = QApplication.instance()\n",
    "    \n",
    "    clients = [CameraClient(host, config.NETWORK_PORT) for host in config.SERVER_HOSTS]\n",
    "    for client in clients: client.start()\n",
    "\n",
    "    processing_thread = QThread()\n",
    "    processing_worker = ProcessingWorker()\n",
    "    processing_worker.moveToThread(processing_thread)\n",
    "    \n",
    "    window = VisualizationWindow()\n",
    "    \n",
    "    processing_thread.started.connect(processing_worker.run)\n",
    "    processing_worker.new_data.connect(window.update_plot)\n",
    "    \n",
    "    def cleanup():\n",
    "        logging.info(\"Application cleanup initiated.\")\n",
    "        processing_worker.stop()\n",
    "        processing_thread.quit(); processing_thread.wait()\n",
    "        for client in clients: client.stop(); client.join()\n",
    "        logging.info(\"Cleanup complete.\")\n",
    "    \n",
    "    app.aboutToQuit.connect(cleanup)\n",
    "    \n",
    "    processing_thread.start()\n",
    "    window.show()\n",
    "    \n",
    "    # This is important for running in environments like Jupyter\n",
    "    # It starts the event loop and handles window events\n",
    "    app.exec_()\n",
    "\n",
    "# Run the visualization\n",
    "run_visualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
